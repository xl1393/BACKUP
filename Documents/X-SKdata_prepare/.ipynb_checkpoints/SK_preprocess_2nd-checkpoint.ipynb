{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import scipy.ndimage as nd\n",
    "import re\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    "import h5py\n",
    "from skimage.util import view_as_blocks\n",
    "\n",
    "\n",
    "def Down_Sample(image, block_size, func=np.sum, cval=0):\n",
    "\n",
    "    if len(block_size) != image.ndim:\n",
    "        raise ValueError(\"`block_size` must have the same length \"\n",
    "                         \"as `image.shape`.\")\n",
    "\n",
    "    pad_width = []\n",
    "    for i in range(len(block_size)):\n",
    "        if block_size[i] < 1:\n",
    "            raise ValueError(\"Down-sampling factors must be >= 1. Use \"\n",
    "                             \"`skimage.transform.resize` to up-sample an \"\n",
    "                             \"image.\")\n",
    "        if image.shape[i] % block_size[i] != 0:\n",
    "            after_width = block_size[i] - (image.shape[i] % block_size[i])\n",
    "        else:\n",
    "            after_width = 0\n",
    "        pad_width.append((0, after_width))\n",
    "\n",
    "    image = np.pad(image, pad_width=pad_width, mode='constant',\n",
    "                   constant_values=cval)\n",
    "\n",
    "    out = view_as_blocks(image, block_size)\n",
    "\n",
    "    for i in range(len(out.shape) // 2):\n",
    "        out = func(out, axis=-1)\n",
    "\n",
    "    return out\n",
    "\n",
    "def RmIsolated_pixel(img):\n",
    "\n",
    "    sat = np.pad(img, pad_width=1, mode='constant', constant_values=0)\n",
    "    sat = np.cumsum(np.cumsum(sat, axis=0), axis=1)\n",
    "    sat = np.pad(sat, ((1, 0), (1, 0)), mode='constant', constant_values=0)\n",
    "    # These are all the possible overlapping 3x3 windows sums\n",
    "    sum3x3 = sat[3:, 3:] + sat[:-3, :-3] - sat[3:, :-3] - sat[:-3, 3:]\n",
    "    # This takes away the central pixel value\n",
    "    sum3x3 -= img\n",
    "    # This zeros all the isolated pixels\n",
    "    img[sum3x3 == 0] = 0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generic_laplace(input, derivative2, output=None, mode=\"reflect\",\n",
    "                    cval=0.0,\n",
    "                    extra_arguments=(),\n",
    "                    extra_keywords = None):\n",
    "    \"\"\"N-dimensional Laplace filter using a provided second derivative function\n",
    "    Parameters\n",
    "    ----------\n",
    "    %(input)s\n",
    "    derivative2 : callable\n",
    "        Callable with the following signature::\n",
    "            derivative2(input, axis, output, mode, cval,\n",
    "                        *extra_arguments, **extra_keywords)\n",
    "        See `extra_arguments`, `extra_keywords` below.\n",
    "    %(output)s\n",
    "    %(mode)s\n",
    "    %(cval)s\n",
    "    %(extra_keywords)s\n",
    "    %(extra_arguments)s\n",
    "    \"\"\"\n",
    "    if extra_keywords is None:\n",
    "        extra_keywords = {}\n",
    "    input = numpy.asarray(input)\n",
    "    output, return_value = _ni_support._get_output(output, input)\n",
    "    axes = list(range(input.ndim))\n",
    "    if len(axes) > 0:\n",
    "        derivative2(input, axes[0], output, mode, cval,\n",
    "                    *extra_arguments, **extra_keywords)\n",
    "        for ii in range(1, len(axes)):\n",
    "            tmp = derivative2(input, axes[ii], output.dtype, mode, cval,\n",
    "                              *extra_arguments, **extra_keywords)\n",
    "            output += tmp\n",
    "    else:\n",
    "        output[...] = input[...]\n",
    "    return return_value\n",
    "\n",
    "def gaussian_laplace(input, sigma, output=None, mode=\"reflect\",\n",
    "                     cval=0.0, **kwargs):\n",
    "    \"\"\"Multidimensional Laplace filter using gaussian second derivatives.\n",
    "    Parameters\n",
    "    ----------\n",
    "    %(input)s\n",
    "    sigma : scalar or sequence of scalars\n",
    "        The standard deviations of the Gaussian filter are given for\n",
    "        each axis as a sequence, or as a single number, in which case\n",
    "        it is equal for all axes.\n",
    "    %(output)s\n",
    "    %(mode)s\n",
    "    %(cval)s\n",
    "    Extra keyword arguments will be passed to gaussian_filter().\n",
    "    \"\"\"\n",
    "    input = numpy.asarray(input)\n",
    "\n",
    "    def derivative2(input, axis, output, mode, cval, sigma, **kwargs):\n",
    "        order = [0] * input.ndim\n",
    "        order[axis] = 2\n",
    "        return gaussian_filter(input, sigma, order, output, mode, cval,\n",
    "                               **kwargs)\n",
    "\n",
    "    return generic_laplace(input, derivative2, output, mode, cval,\n",
    "                           extra_arguments=(sigma,),\n",
    "                           extra_keywords=kwargs)\n",
    "\n",
    "\n",
    "def hist_match(source, template):\n",
    "    \"\"\"\n",
    "    Adjust the pixel values of a grayscale image such that its histogram\n",
    "    matches that of a target image\n",
    "\n",
    "    Arguments:\n",
    "    -----------\n",
    "        source: np.ndarray\n",
    "            Image to transform; the histogram is computed over the flattened\n",
    "            array\n",
    "        template: np.ndarray\n",
    "            Template image; can have different dimensions to source\n",
    "    Returns:\n",
    "    -----------\n",
    "        matched: np.ndarray\n",
    "            The transformed output image\n",
    "    \"\"\"\n",
    "\n",
    "    oldshape = source.shape\n",
    "    source = source.ravel()\n",
    "    template = template.ravel()\n",
    "\n",
    "    # get the set of unique pixel values and their corresponding indices and\n",
    "    # counts\n",
    "    s_values, bin_idx, s_counts = np.unique(source, return_inverse=True,\n",
    "                                            return_counts=True)\n",
    "    t_values, t_counts = np.unique(template, return_counts=True)\n",
    "\n",
    "    # take the cumsum of the counts and normalize by the number of pixels to\n",
    "    # get the empirical cumulative distribution functions for the source and\n",
    "    # template images (maps pixel value --> quantile)\n",
    "    s_quantiles = np.cumsum(s_counts).astype(np.float64)\n",
    "    s_quantiles /= s_quantiles[-1]\n",
    "    t_quantiles = np.cumsum(t_counts).astype(np.float64)\n",
    "    t_quantiles /= t_quantiles[-1]\n",
    "\n",
    "    # interpolate linearly to find the pixel values in the template image\n",
    "    # that correspond most closely to the quantiles in the source image\n",
    "    interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)\n",
    "\n",
    "    return interp_t_values[bin_idx].reshape(oldshape)\n",
    "\n",
    "def hist_match_color(source,template):\n",
    "    b_source=source[:,:,0]\n",
    "    g_source=source[:,:,1]\n",
    "    r_source=source[:,:,2]\n",
    "    \n",
    "    b_template=template[:,:,0]\n",
    "    g_template=template[:,:,1]\n",
    "    r_template=template[:,:,2]\n",
    "    \n",
    "    b_matched=hist_match(b_source,b_template)\n",
    "    g_matched=hist_match(g_source,g_template)\n",
    "    r_matched=hist_match(r_source,r_template)\n",
    "    \n",
    "    matched=cv2.merge([b_matched,g_matched,r_matched])\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def info(img8):\n",
    "    print img8.dtype\n",
    "    print img8.shape\n",
    "    print type(img8)\n",
    "    print np.max(img8)\n",
    "    print np.min(img8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetBlockList(overlap=10/2):\n",
    "    x1=0\n",
    "    y1=256\n",
    "    blocklist=[]\n",
    "    count = 0\n",
    "    while (x1+256<10000):\n",
    "        x2=0\n",
    "        y2=256\n",
    "        while (x2+256<12000):\n",
    "            blocklist.append(np.asarray([x1,y1,x2,y2,count]))\n",
    "            count = count + 1\n",
    "            x2=y2-overlap\n",
    "            y2=x2+512/2\n",
    "        x1=y1-overlap\n",
    "        y1=x1+512/2\n",
    "    return blocklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetNO(filename):\n",
    "    return int(filename[-17:-13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def blockprocess(img,metadata,filecount):\n",
    "    #print type(metadata)\n",
    "    sub=img[metadata[0]:metadata[1],metadata[2]:metadata[3]]\n",
    "    #Gmask= np.max(sub,axis=2) != sub[:,:,1]\n",
    "    #sub[Gmask]=0\n",
    "    #sub[sub[:,:,1]<50] =0\n",
    "    #sub=cv2.cvtColor(sub,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite('/scratch/PMD1475_SK/'+str(metadata[4])+'/'+str(filecount)+'.jp2',sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneFileprocess(filename):\n",
    "    print 'processing '+filename\n",
    "    start_time = time.time()\n",
    "    \n",
    "    img=cv2.imread(filename,-1)\n",
    "    \n",
    "    img=cv2.medianBlur(img,3)\n",
    "    LOG=nd.gaussian_laplace(img,3)\n",
    "    #mediancp=np.copy(median)\n",
    "    mask1 = LOG[:,:,0] + LOG[:,:,1] + LOG[:,:,2] < 1000      #background noise 40\n",
    "    mask2 = img[:,:,1] < 500                             #not strong green (need to replace by better detect) 70\n",
    "    mask3 = np.max(img[:,:,:],axis=2) == img[:,:,2]   #looks red(need to replace by autofluo detect)\n",
    "\n",
    "    img[mask1 & mask2] = 0 \n",
    "    img[mask3] = 0\n",
    "\n",
    "    img=np.asarray(img,'uint8')\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=cv2.equalizeHist(img)\n",
    "\n",
    "    img=Down_Sample(img,block_size=(2,2),func=np.mean)\n",
    "    cv2.imwrite('/scratch/PMD1475_NOCUT/'+os.path.basename(filename),img)\n",
    "\n",
    "    blocks=GetBlockList()\n",
    "    for k in blocks:\n",
    "        blockprocess(img,k,GetNO(filename))\n",
    "        \n",
    "    print ('Finishing ' + filename + ', took %s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#main\n",
    "inputfolder='/scratch/PMD1475/*.jp2'\n",
    "filelist=natural_sort(glob.glob(inputfolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /scratch/PMD1475/PMD1476&1475-F2-2014.02.10-15.53.15_PMD1475_1_0004_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F4-2014.02.10-16.26.31_PMD1475_2_0011_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F16-2014.02.10-20.00.17_PMD1475_2_0047_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F14-2014.02.10-19.18.42_PMD1475_1_0040_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F9-2014.02.10-17.51.33_PMD1475_1_0025_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F18-2014.02.10-20.41.55_PMD1475_3_0054_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F6-2014.02.10-17.00.14_PMD1475_3_0018_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F11-2014.02.10-18.28.20_PMD1475_2_0032_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F21-2014.02.11-08.52.13_PMD1475_1_0061_lossless.jp2\n",
      "processing /scratch/PMD1475/PMD1476&1475-F23-2014.02.11-09.35.38_PMD1475_2_0068_lossless.jp2\n"
     ]
    }
   ],
   "source": [
    "p=Pool(10)\n",
    "p.map(OneFileprocess,filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
